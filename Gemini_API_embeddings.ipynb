{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Gemini API: Embeddings\n",
        "## Importing libraries"
      ],
      "metadata": {
        "id": "zEaeSnHm0dio"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U -q google-generativeai"
      ],
      "metadata": {
        "id": "-WfUmQ6U0gZi"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import google.generativeai as genai"
      ],
      "metadata": {
        "id": "VTAzuPzk0nDb"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Configuring API"
      ],
      "metadata": {
        "id": "Rvx5Eeqk0rkG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "\n",
        "GOOGLE_API_KEY=userdata.get('GOOGLE_API_KEY')\n",
        "genai.configure(api_key=GOOGLE_API_KEY)"
      ],
      "metadata": {
        "id": "PeR2RKe70tLI"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "An **embedding** is a list of decimal point numbers that represent the meaning of a word/sentence/paragraph. A quantity of these numbers represent dimensionality of embeddings.\n",
        "\n",
        "Embeddings can be used in document search, anomaly detection, text classification, and many other tasks!\n",
        "\n",
        "Generating embeddings\n",
        "To generate embeddings for a given data, use `embed_content` method and pass in which `model` to use and what `content` to convert:\n",
        "\n",
        "-`model`: Required. Must be either `models/text-embedding-004` or `models/embedding-001`.\n",
        "\n",
        "- `content`: Required. The data to embed.\n",
        "\n",
        "- `output_dimensionality`: Optional. Reduced dimension for the output embedding. If set, excessive values in the output embedding are truncated from the end. This is supported by `models/text-embedding-004`, but cannot be specified in `models/embedding-001`.\n",
        "\n",
        "- `task_type`: Optional. The task type for which the embeddings will be used.\n",
        "\n",
        "- `title`: Optional. You should only set this parameter if your task type is `retrieval_document` (or `document`).\n",
        "\n",
        "(The latter three will be explored later.)\n",
        "\n",
        "Here, we will use `models/text-embedding-004` to generate text embeddings:"
      ],
      "metadata": {
        "id": "c_VcNb171DLY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = 'Hi there, this is Gemini tutorial!'\n",
        "\n",
        "embed_data = genai.embed_content(\n",
        "    model='models/text-embedding-004',\n",
        "    content=data\n",
        ")"
      ],
      "metadata": {
        "id": "maHwDE_815Rk"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since embeddings can have large dimensionality (i.e. length), we will output only first 10 values:"
      ],
      "metadata": {
        "id": "xG4WIcF22LLk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(embed_data['embedding'][:10])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O_tSYcyZ2Sxu",
        "outputId": "befe59d6-a59a-430e-e846-8b6d9e1bdf43"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.05843896, 0.0004431678, -0.009973633, -0.016529618, 0.041487474, -0.013944048, 0.08006431, 0.055516902, -0.03406745, 0.046189807]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "By default, the embeddings have dimensionality of 768:"
      ],
      "metadata": {
        "id": "dIrngBV22Ucq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(embed_data['embedding']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tLll8_f22MCp",
        "outputId": "25bcf94d-5ffb-45fb-c38b-dd1767ae4e04"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "768\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Instead of a single string values, we can also pass in a batch of data (i.e. a list of strings):"
      ],
      "metadata": {
        "id": "4_Bb8qI52bWS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = [\n",
        "    'What is the tuition at UC Berkeley?',\n",
        "    'Name top 10 books about machine learning.',\n",
        "    'How to stop procrastinating?'\n",
        "]\n",
        "\n",
        "embed_data = genai.embed_content(\n",
        "    model='models/text-embedding-004',\n",
        "    content=data\n",
        ")"
      ],
      "metadata": {
        "id": "lJCSd5yq2cDP"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for embedding in embed_data['embedding']:\n",
        "    print(embedding[:10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_kRF6jaG2kOK",
        "outputId": "09452c93-a0bd-46e0-e413-164bfc90958e"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.055581044, 0.06622884, -0.083276704, -0.0021693043, 0.02703125, 0.0060264487, 0.02783055, -0.017377941, -0.052792866, 0.035122644]\n",
            "[0.017529475, -0.026426781, 0.0011475772, -0.022670647, -0.03672292, 0.009089401, -0.02183994, 0.022415891, -0.021802155, -0.02764353]\n",
            "[0.0039839307, -0.02675414, 0.06129221, -0.013258428, -0.024475494, 0.04371136, -0.008513142, 0.012199538, 0.024706287, -0.0123653505]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This allows us to use a single API call more efficiently (instead of calling multiple times)."
      ],
      "metadata": {
        "id": "mtSSwO112gMS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Truncating embeddings\n",
        "To reduce dimensionality of embeddings, we can specify it with `output_dimensionality` argument:"
      ],
      "metadata": {
        "id": "FK0Db5-A0pM5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embed_data = genai.embed_content(\n",
        "    model='models/text-embedding-004',\n",
        "    content='Below is how you truncate data!',\n",
        "    output_dimensionality=10\n",
        ")"
      ],
      "metadata": {
        "id": "9qWI58id20Rl"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, the dimensionality of the output is restricted by 10:"
      ],
      "metadata": {
        "id": "5USFTrVN24TR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(embed_data['embedding']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "soCScy3A25Ib",
        "outputId": "6d950fd8-4ee8-4e4f-c79b-8f880b183438"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Specifying embeddings\n",
        "Since there are many different tasks where embeddings are used, you can refine them specifying for which one of the following `task_type`'s you are using embeddings for:\n",
        "\n",
        "- `unspecified`: If you do not set the value, it will default to retrieval_query.\n",
        "\n",
        "- `retrieval_query` (or `query`): The given text is a query in a search/retrieval setting.\n",
        "\n",
        "- `retrieval_document` (or `document`): The given text is a document from a corpus being searched. Optionally, also set the title parameter with the title of the document.\n",
        "\n",
        "- `semantic_similarity` (or `similarity`): The given text will be used for Semantic Textual Similarity (STS).\n",
        "\n",
        "- `classification`: The given text will be classified.\n",
        "\n",
        "- `clustering`: The embeddings will be used for clustering.\n",
        "\n",
        "- `question_answering`: The given text will be used for question answering.\n",
        "\n",
        "- `fact_verification`: The given text will be used for fact verification.\n",
        "\n",
        "Depending on the `task_type`, embeddings differ:"
      ],
      "metadata": {
        "id": "B8FAbnk23B0V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = 'Finally touching the grass!'\n",
        "\n",
        "embed_data_1 = genai.embed_content(\n",
        "    model='models/text-embedding-004',\n",
        "    content=data\n",
        "    # no `task_type` specification; defaults to `retrieval_query`\n",
        ")\n",
        "\n",
        "embed_data_2 = genai.embed_content(\n",
        "    model='models/text-embedding-004',\n",
        "    content=data,\n",
        "    task_type='retrieval_document'\n",
        ")\n",
        "\n",
        "print(embed_data_1['embedding'][:10])\n",
        "print(embed_data_2['embedding'][:10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "YJ8b7tL-3htN",
        "outputId": "2bae2d9a-f01d-43dc-f72a-d7c07c4be3b4"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[-0.044086628, -0.017505977, -0.014579225, 0.013675356, -0.008016502, 0.025225218, -0.035069168, 0.034015443, 0.03730417, 0.007439851]\n",
            "[-0.023972979, -0.019189889, -0.022257302, -0.012185106, 0.019129643, 0.035173625, -0.012367235, 0.016283924, 0.02262941, 0.014976868]\n"
          ]
        }
      ]
    }
  ]
}